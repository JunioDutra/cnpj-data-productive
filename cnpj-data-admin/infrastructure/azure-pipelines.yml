trigger:
  branches:
    include:
      - main
      - master

pool:
  name: Default

resources:
- repo: self

variables:
  tag: '$(Build.BuildId)'
  repositoryPrefix: '192.168.2.177:32768'
  repository: 'app_web_admin'
  repositoryProxy: 'api-proxy'
  projectNamespace: 'cnpj-data'
  AWS_ACCESS_KEY_ID: '$(MINIO_ACCESS_KEY)'
  AWS_SECRET_ACCESS_KEY: '$(MINIO_SECRET_KEY)'
  AWS_ENDPOINT_URL: '$(MINIO_ENDPOINT_URL)'
  MINIO_S3_BUCKET_NAME: '$(MINIO_S3_BUCKET_NAME)'

stages:
- stage: Build_And_Deploy
  displayName: Build and Deploy
  jobs:
  - job: BuildAndDeploy
    displayName: Build React App and Deploy to MinIO S3
    steps:
    - script: |
        # Ensure we're in the correct directory
        cd $(Pipeline.Workspace)/s/cnpj-data-admin
        
        # Debug: Show current working directory and verify files
        echo "Current working directory: $(pwd)"
        echo "Contents of current directory:"
        ls -la
        echo "Checking package.json content:"
        head -5 package.json
        
        # Build using Docker with explicit bind mount
        docker run --rm \
          --mount type=bind,source="$(pwd)",target=/workspace \
          -w /workspace \
          -e VITE_OIDC_ENDPOINT=https://iam.dblsoft.xyz/ \
          -e VITE_OIDC_REALM=apps \
          -e VITE_OIDC_CLIENT=app \
          -e VITE_API_URL=https://company-api.dblsoft.xyz \
          node:18-alpine \
          sh -c "echo 'Contents of /workspace:' && ls -la /workspace && echo 'Checking package.json:' && cat /workspace/package.json | head -10 && echo 'Installing dependencies...' && npm ci --only=production --no-audit && echo 'Building application...' && npm run build && echo 'Build completed. Contents of dist:' && ls -la dist/"
      displayName: 'Build React App with Docker (bind mount)'
    
    - script: |
        # Ensure we're in the correct directory
        cd $(Pipeline.Workspace)/s/cnpj-data-admin
        
        # Check if dist directory exists and has content
        echo "Contents of dist directory:"
        ls -la dist/
        
        # Deploy to MinIO S3 using AWS CLI Docker image
        docker run --rm \
          -v "$(pwd)/dist":/dist \
          -e AWS_ACCESS_KEY_ID="$(AWS_ACCESS_KEY_ID)" \
          -e AWS_SECRET_ACCESS_KEY="$(AWS_SECRET_ACCESS_KEY)" \
          -e AWS_DEFAULT_REGION="us-east-1" \
          amazon/aws-cli:latest \
          s3 sync /dist s3://$(MINIO_S3_BUCKET_NAME)/ \
            --endpoint-url $(AWS_ENDPOINT_URL) \
            --delete \
            --cache-control "public, max-age=31536000" \
            --exclude "*.html" \
            --exclude "*.json"
        
        # Upload HTML and JSON files with no-cache
        docker run --rm \
          -v "$(pwd)/dist":/dist \
          -e AWS_ACCESS_KEY_ID="$(AWS_ACCESS_KEY_ID)" \
          -e AWS_SECRET_ACCESS_KEY="$(AWS_SECRET_ACCESS_KEY)" \
          -e AWS_DEFAULT_REGION="us-east-1" \
          amazon/aws-cli:latest \
          s3 sync /dist s3://$(MINIO_S3_BUCKET_NAME)/ \
            --endpoint-url $(AWS_ENDPOINT_URL) \
            --include "*.html" \
            --include "*.json" \
            --cache-control "no-cache, no-store, must-revalidate"
      displayName: 'Deploy to MinIO S3'

    - task: DockerCompose@1
      inputs:
        containerregistrytype: 'Container Registry'
        dockerRegistryEndpoint: 'docker-service-connection-apps'
        dockerComposeFile: '$(Pipeline.Workspace)/s/compose.yml'
        projectName: '$(repository)'
        action: 'Run a Docker Compose command'
        dockerComposeCommand: 'up --build'
        arguments: '-d'
